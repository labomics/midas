{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/root/workspace/code/midas/\")\n",
    "from os.path import join as pj\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.append(\"modules\")\n",
    "import utils\n",
    "import numpy as np\n",
    "import scib\n",
    "import scib.metrics as me\n",
    "import anndata as ad\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='teadog_single')\n",
    "parser.add_argument('--experiment', type=str, default='e0')\n",
    "parser.add_argument('--model', type=str, default='default')\n",
    "parser.add_argument('--init_model', type=str, default='sp_00001899')\n",
    "# parser.add_argument('--method', type=str, default='stabmap')\n",
    "parser.add_argument('--method', type=str, default='midas_embed')\n",
    "o, _ = parser.parse_known_args()  # for python interactive\n",
    "# o = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"midas\" in o.method:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method, o.experiment, o.model, o.init_model)\n",
    "else:\n",
    "    result_dir = pj(\"result\", \"comparison\", o.task, o.method)\n",
    "cfg_task = re.sub(\"_vd.*|_vt.*|_atlas|_generalize|_transfer|_ref_.*\", \"\", o.task)\n",
    "data_config = utils.load_toml(\"configs/data.toml\")[cfg_task]\n",
    "for k, v in data_config.items():\n",
    "    vars(o)[k] = v\n",
    "model_config = utils.load_toml(\"configs/model.toml\")[\"default\"]\n",
    "if o.model != \"default\":\n",
    "    model_config.update(utils.load_toml(\"configs/model.toml\")[o.model])\n",
    "for k, v in model_config.items():\n",
    "    vars(o)[k] = v\n",
    "o.s_joint, o.combs, *_ = utils.gen_all_batch_ids(o.s_joint, o.combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B' 'CD4 T' 'CD8 T' 'DC' 'Mono' 'NK' 'other' 'other T']\n"
     ]
    }
   ],
   "source": [
    "# Load cell type labels\n",
    "labels = []\n",
    "label_file = \"l1_\" + o.task.split(\"_\")[-1] + \".csv\" if \"_vt\" in o.task else \"l1.csv\"\n",
    "for raw_data_dir in o.raw_data_dirs:\n",
    "    label = utils.load_csv(pj(raw_data_dir, \"label_seurat\", label_file))\n",
    "    labels += utils.transpose_list(label)[1][1:]\n",
    "labels = np.array(labels)\n",
    "print(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading predicted variables ...\n",
      "Loading subset 0: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 303.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 1: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 322.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 2: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:00<00:00, 294.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subset 3: z, joint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:00<00:00, 332.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to numpy ...\n",
      "Converting subset 0: s, joint\n",
      "Converting subset 0: z, joint\n",
      "Converting subset 1: s, joint\n",
      "Converting subset 1: z, joint\n",
      "Converting subset 2: s, joint\n",
      "Converting subset 2: z, joint\n",
      "Converting subset 3: s, joint\n",
      "Converting subset 3: z, joint\n"
     ]
    }
   ],
   "source": [
    "# Load predicted latent variables\n",
    "o.mods = [\"atac\", \"rna\", \"adt\"]\n",
    "o.pred_dir = pj(\"result\", o.task, o.experiment, o.model, \"predict\", o.init_model)\n",
    "pred = utils.load_predicted(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if o.method in [\"midas_embed\", \"mofa\", \"scmomat\", \"stabmap\", \"scvaeit\", \"multigrate\", \"glue\"]:\n",
    "    output_type = \"embed\"\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    output_type = \"graph\"\n",
    "else:\n",
    "    assert False, o.method+\": invalid method!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = \"X_emb\"\n",
    "batch_key = \"batch\"\n",
    "label_key = \"label\"\n",
    "cluster_key = \"cluster\"\n",
    "si_metric = \"euclidean\"\n",
    "subsample = 0.5\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pred[\"z\"][\"joint\"][:, :o.dim_c]\n",
    "s = pred[\"s\"][\"joint\"]\n",
    "\n",
    "if o.method == \"midas_embed\":\n",
    "    adata = ad.AnnData(c)\n",
    "    adata.obsm[embed] = c\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"mofa\", \"stabmap\", \"multigrate\", \"glue\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings)[1:, 1:].astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\"scmomat\", \"scvaeit\"]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    embeddings = utils.load_csv(pj(result_dir, \"embeddings.csv\"))\n",
    "    adata.obsm[embed] = np.array(embeddings).astype(np.float32)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "elif o.method in [\n",
    "    \"midas_feat+wnn\", \n",
    "    \"harmony+wnn\", \n",
    "    \"pca+wnn\",\n",
    "    \"seurat_cca+wnn\",\n",
    "    \"seurat_rpca+wnn\",\n",
    "    \"scanorama_embed+wnn\",\n",
    "    \"scanorama_feat+wnn\",\n",
    "    \"liger+wnn\",\n",
    "    \"bbknn\",\n",
    "    ]:\n",
    "    adata = ad.AnnData(c*0)\n",
    "    adata.obs[batch_key] = s.astype(str)\n",
    "    adata.obs[batch_key] = adata.obs[batch_key].astype(\"category\")\n",
    "    adata.obs[label_key] = labels\n",
    "    adata.obs[label_key] = adata.obs[label_key].astype(\"category\")\n",
    "    adata.obsp[\"connectivities\"] = scipy.io.mmread(pj(result_dir, \"connectivities.mtx\")).tocsr()\n",
    "    adata.uns[\"neighbors\"] = {'connectivities_key': 'connectivities'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "print('clustering...')\n",
    "res_max, nmi_max, nmi_all = scib.clustering.opt_louvain(adata, label_key=label_key,\n",
    "    cluster_key=cluster_key, function=me.nmi, use_rep=embed, verbose=verbose, inplace=True)\n",
    "\n",
    "results['NMI'] = me.nmi(adata, group1=cluster_key, group2=label_key, method='arithmetic')\n",
    "print(\"NMI: \" + str(results['NMI']))\n",
    "\n",
    "results['ARI'] = me.ari(adata, group1=cluster_key, group2=label_key)\n",
    "print(\"ARI: \" + str(results['ARI']))\n",
    "\n",
    "type_ = \"knn\" if output_type == \"graph\" else None\n",
    "results['kBET'] = me.kBET(adata, batch_key=batch_key, label_key=label_key, embed=embed, \n",
    "    type_=type_, verbose=verbose)\n",
    "print(\"kBET: \" + str(results['kBET']))\n",
    "\n",
    "results['il_score_f1'] = me.isolated_labels(adata, label_key=label_key, batch_key=batch_key,\n",
    "    embed=embed, cluster=True, verbose=verbose)\n",
    "print(\"il_score_f1: \" + str(results['il_score_f1']))\n",
    "\n",
    "results['graph_conn'] = me.graph_connectivity(adata, label_key=label_key)\n",
    "print(\"graph_conn: \" + str(results['graph_conn']))\n",
    "\n",
    "results['cLISI'] = me.clisi_graph(adata, batch_key=batch_key, label_key=label_key, type_=\"knn\",\n",
    "    subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "print(\"cLISI: \" + str(results['cLISI']))\n",
    "\n",
    "results['iLISI'] = me.ilisi_graph(adata, batch_key=batch_key, type_=\"knn\",\n",
    "    subsample=subsample*100, n_cores=1, verbose=verbose)\n",
    "print(\"iLISI: \" + str(results['iLISI']))\n",
    "\n",
    "results = {k: float(v) for k, v in results.items()}\n",
    "# results['batch_score'] = np.nanmean([results['iLISI'], results['graph_conn'], results['kBET']])\n",
    "# results['bio_score'] = np.nanmean([results['NMI'], results['ARI'], results['il_score_f1'], results['cLISI']])\n",
    "# results[\"overall_score\"] = float(0.4 * results['batch_score'] + 0.6 * results['bio_score'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'iLISI':          [results['iLISI']],\n",
    "    'graph_conn':     [results['graph_conn']],\n",
    "    'kBET':           [results['kBET']],\n",
    "    # 'batch_score':    [results['batch_score']],\n",
    "    'NMI':            [results['NMI']],\n",
    "    'ARI':            [results['ARI']],\n",
    "    'il_score_f1':    [results['il_score_f1']],\n",
    "    'cLISI':          [results['cLISI']],\n",
    "    # 'bio_score':      [results['bio_score']],\n",
    "    # 'overall_score':  [results['overall_score']]\n",
    "})\n",
    "print(df)\n",
    "utils.mkdirs(result_dir, remove_old=False)\n",
    "df.to_excel(pj(result_dir, \"metrics_batch_bio.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
